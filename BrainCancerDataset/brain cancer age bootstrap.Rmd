---
title: "brian cancer age new bootstrap"
author: "Aoife Clarke"
date: "2025-03-12"
output: html_document
---


```{r include=FALSE}
#Required packages
library(Biobase)
library(mclust)
library(clue)
library(pdfCluster)
library(NMF)
library(funtimes)
library(ggplot2)
library(plotrix)
library(fpc)
library(cluster)
library(aricode)
library(dplyr)
library(corrplot)
library(limma)
library(tidyr)
library(DESeq2)
library(kableExtra)
library(edgeR)

```

```{r}
#Read in gene expression data and covert it to matrix formation
exprs <- as.matrix(read.delim("C:/Users/aoife/OneDrive/Documents/BI453 - Project/AllBrainCancermatrix.txt", header = TRUE, row.names = 1, sep = "\t", as.is = TRUE))

```

```{r}
# Data Preprocessing

# Step 1: Replace any NA with the average value of non-NA values across that row

exprs <- t(apply(exprs, 1, function(row) {
  missing_values <- is.na(row)
  if (any(!missing_values)) {
    mean_value <- mean(row[!missing_values], na.rm = TRUE)
    row[missing_values] <- mean_value
  }
  return(row)
}))

```

```{r}
# Step 2: Remove all genes with zero values across the rows

exprs <- exprs[apply(exprs, 1, function(row) all(row !=0 )), ]

```

```{r}
# Step 3: Select the top 1000 most variably expressed genes

exprs <- exprs[order(apply(exprs, 1, var), decreasing = TRUE)[1:1000], ]

```

```{r}
#Read in the file containing sample data
pdata <- read.delim("C:/Users/aoife/OneDrive/Documents/BI453 - Project/Brainsamples.txt", row.names = 1, header = FALSE, sep = "\t")
head(pdata)

#Read in the file containing feature data i.e. genes
fdata <- read.delim("C:/Users/aoife/OneDrive/Documents/BI453 - Project/Brainfeatures.txt", row.names = 1, header = FALSE, sep = "\t")
head(fdata)

```
```{r}
#Makes an expression set from the expression matrix, phenotype data (sample), feature data (gene)
eset <- ExpressionSet(assayData = exprs,
                      phenoData = AnnotatedDataFrame(pdata),
                      featureData = AnnotatedDataFrame(fdata))

```

```{r}
#Assign the expression matrix as 'A'
A <- exprs(eset)
dim(A)
head(A)

```

```{r}
#Read in file containing subtype and gender tables and assign to 'Corresdata'
Corresdata <- read.delim("C:/Users/aoife/OneDrive/Documents/BI453 - Project/BrainCancerLabels.txt", header = TRUE, sep = "\t", as.is = TRUE)

```

```{r}
Corresdatalabels <- Corresdata$IDH.1p19q.Subtype
```

```{r}
#Creating a vector with the ground truths for all samples
groundtruths <- ifelse(Corresdatalabels == 'IDHmut-non-codel', 1, 
                     ifelse(Corresdatalabels == 'IDHmut-codel', 2, NA))
head(groundtruths)
unique(groundtruths)

```
```{r}
names(groundtruths) <- rownames(Corresdata)


print(table(groundtruths))

```

```{r}
print(table(Corresdata$age_at_initial_pathologic))
```
```{r}
rownames(Corresdata) <- Corresdata$Tumor
```

```{r}
aligned_samples <- match(colnames(exprs), rownames(Corresdata))
sum(is.na(aligned_samples))

```
```{r}
# Check for samples with missing age
na_samples <- rownames(Corresdata)[is.na(Corresdata$age_at_initial_pathologic)]
print(na_samples)  

```

```{r}
# Remove samples with missing age from Corresdata
Corresdata <- Corresdata[!rownames(Corresdata) %in% na_samples, ]


common_samples <- intersect(colnames(exprs), rownames(Corresdata))

```

```{r}
exprs <- exprs[, common_samples]

# Subset Corresdata to the common samples
aligned_metadata <- Corresdata[common_samples, ]

dim(exprs)

```

```{r}
# Removing DEGs between ages


median_age <- median(Corresdata$age_at_initial_pathologic, na.rm = TRUE)
age_group <- ifelse(Corresdata$age_at_initial_pathologic > median_age, "High", "Low")


age_group <- factor(age_group, levels = c("High", "Low"))

# Create a design matrix for age groups
design_age <- model.matrix(~ age_group)
colnames(design_age) <- c("Intercept", "High_vs_Low")


fit_age <- lmFit(exprs, design_age)
fit_age <- eBayes(fit_age)

# Extract DEGs
deg_results_age <- topTable(fit_age, coef = "High_vs_Low", number = Inf, sort.by = "none", adjust.method = "fdr")

# Filter DEGs 
de_genes_age <- rownames(deg_results_age[deg_results_age$adj.P.Val < 0.1 & abs(deg_results_age$logFC) > 0.5, ])

# Remove DEGs from the expression matrix
exprs_filtered_ages <- exprs[!(rownames(exprs) %in% de_genes_age), ]

```

```{r}
dim(exprs)
dim(exprs_filtered_ages)
```

```{r}
# Non-Negative Matrix Factorization

# Set the rank 
rank <- 2
num_runs <- 100


nmf_results_original <- list()
nmf_results_filtered <- list()

# Run NMF on original and filtered expression matrices
for (x in 1:num_runs) {
  nmf_result_original <- nmf(exprs, rank = rank, nrun = 1, seed = "random")
  nmf_results_original[[as.character(x)]] <- nmf_result_original
  
  nmf_result_filtered <- nmf(exprs_filtered_ages, rank = rank, nrun = 1, seed = "random")
  nmf_results_filtered[[as.character(x)]] <- nmf_result_filtered
}

```

```{r}
names(groundtruths) <- colnames(exprs)

```


```{r}
# Creating Cluster Predictions

# store cluster predictions
predictions_original <- list()
predictions_filtered <- list()

# Generate cluster assignments for each NMF run
for (x in 1:num_runs) {
  
# Original dataset clustering
  H_matrix <- coef(nmf_results_original[[x]])  
  cluster_predictions <- apply(H_matrix, 2, which.max)  
  names(cluster_predictions) <- colnames(exprs)  
  

  predictions_original[[as.character(x)]] <- unify_labels(cluster_predictions, groundtruths)

# Filtered dataset clustering
  H_matrix_filtered <- coef(nmf_results_filtered[[x]])  
  cluster_predictions_filtered <- apply(H_matrix_filtered, 2, which.max)  
  names(cluster_predictions_filtered) <- colnames(exprs_filtered_ages)  
  
# Align groundtruths for filtered dataset
  common_samples <- intersect(names(cluster_predictions_filtered), names(groundtruths))
  
  if (length(common_samples) > 0) {
    cluster_predictions_filtered <- cluster_predictions_filtered[common_samples]
    groundtruths_filtered_matched <- groundtruths[common_samples]
    

    predictions_filtered[[as.character(x)]] <- unify_labels(cluster_predictions_filtered, groundtruths_filtered_matched)
  } else {
    
# Store NA if no matching samples 
    predictions_filtered[[as.character(x)]] <- rep(NA, length(cluster_predictions_filtered))
  }
}

# check predictions
print("First few predictions (Original):")
print(head(predictions_original[[1]]))

print("First few predictions (Filtered):")
print(head(predictions_filtered[[1]]))

```

```{r}
# Purity

# Calculate purity 
calculate_purity <- function(predicted_labels, groundtruths) {
  contingency_table <- table(predicted_labels, groundtruths)
  sum(apply(contingency_table, 1, max)) / length(groundtruths)
}

# Purity for each NMF run (Original Data)
purity_original <- sapply(predictions_original, function(pred) {
  pred <- pred[names(groundtruths)]
  if (length(pred) == length(groundtruths)) calculate_purity(pred, groundtruths) else NA
})

# Purity for each NMF run (Filtered Data)
purity_filtered <- sapply(predictions_filtered, function(pred) {
  common_samples <- intersect(names(pred), names(groundtruths))
  if (length(common_samples) > 0) {
    calculate_purity(pred[common_samples], groundtruths[common_samples])
  } else {
    NA
  }
})


summary(purity_original)
summary(purity_filtered)

# Calculate mean purity and standard deviation
purity_average <- list(
  Original = mean(purity_original, na.rm = TRUE),
  Filtered = mean(purity_filtered, na.rm = TRUE)
)

sdpurity <- list(
  Original = sd(purity_original, na.rm = TRUE),
  Filtered = sd(purity_filtered, na.rm = TRUE)
)


print(purity_average)
print(sdpurity)

# Create purity table
purity_table <- data.frame(
  Condition = c("Original", "Filtered"),
  Average_Purity = c(purity_average$Original, purity_average$Filtered),
  SD = c(sdpurity$Original, sdpurity$Filtered)  
)


print(purity_table)

```

```{r}
# Adjusted Rand Index (ARI)

# ARI for each NMF run (Original Data)
ARI_original <- sapply(predictions_original, function(pred) {
  common_samples <- intersect(names(pred), names(groundtruths))
  if (length(common_samples) > 0) {
    adjustedRandIndex(pred[common_samples], groundtruths[common_samples])
  } else {
    NA
  }
})

# ARI for each NMF run (Filtered Data)
ARI_filtered <- sapply(predictions_filtered, function(pred) {
  common_samples <- intersect(names(pred), names(groundtruths))
  if (length(common_samples) > 0) {
    adjustedRandIndex(pred[common_samples], groundtruths[common_samples])
  } else {
    NA
  }
})

# Calculate mean ARI and standard deviation 
ARI_table <- data.frame(
  Condition = c("Original", "Filtered"),
  Average_ARI = c(mean(ARI_original, na.rm = TRUE), mean(ARI_filtered, na.rm = TRUE)),
  SD_ARI = c(sd(ARI_original, na.rm = TRUE), sd(ARI_filtered, na.rm = TRUE)) 
)


print(ARI_table)

```

```{r}
# Find only valid samples 
valid_samples <- names(groundtruths)[!is.na(groundtruths)]


groundtruths_clean <- groundtruths[valid_samples]

# Only include valid samples
predictions_original <- lapply(predictions_original, function(pred) pred[names(pred) %in% valid_samples])
predictions_filtered <- lapply(predictions_filtered, function(pred) pred[names(pred) %in% valid_samples])


print(length(groundtruths_clean))
print(length(predictions_original[[1]]))
print(length(predictions_filtered[[1]]))

```
```{r}
# Find common samples 
common_samples <- Reduce(intersect, list(
  names(groundtruths_clean), 
  names(predictions_original[[1]]), 
  names(predictions_filtered[[1]])
))

# Only include these common samples
groundtruths_clean <- groundtruths_clean[common_samples]
predictions_original <- lapply(predictions_original, function(pred) pred[common_samples])
predictions_filtered <- lapply(predictions_filtered, function(pred) pred[common_samples])

 
print(length(groundtruths_clean))
print(length(predictions_original[[1]]))
print(length(predictions_filtered[[1]]))

```
```{r}
# Normalised Mutual Information

# Remove NA values from groundtruths 
valid_samples <- names(groundtruths)[!is.na(groundtruths)]
groundtruths_clean <- groundtruths[valid_samples]

# NMI for each NMF run on Original 
NMI_original <- sapply(predictions_original, function(pred) {
  common_samples <- intersect(names(pred), valid_samples)  
  if (length(common_samples) > 0) {
    NMI(pred[common_samples], groundtruths_clean[common_samples])
  } else {
    NA
  }
})

# NMI for each NMF run on Filtered 
NMI_filtered <- sapply(predictions_filtered, function(pred) {
  common_samples <- intersect(names(pred), valid_samples)  
  if (length(common_samples) > 0) {
    NMI(pred[common_samples], groundtruths_clean[common_samples])
  } else {
    NA
  }
})

# Calculate mean NMI and standard deviation 
NMI_table <- data.frame(
  Condition = c("Original", "Filtered"),
  Average_NMI = c(mean(NMI_original, na.rm = TRUE), mean(NMI_filtered, na.rm = TRUE)),
  SD_NMI = c(sd(NMI_original, na.rm = TRUE), sd(NMI_filtered, na.rm = TRUE)) 
)


print(NMI_table)

```
```{r}
# Post-Processing - Normalisation 

# Extract W and H matrices 
W_matrices_original <- vector("list", 100)
W_matrices_filtered <- vector("list", 100)
H_matrices_original <- vector("list", 100)
H_matrices_filtered <- vector("list", 100)

# Store extracted basis (W) and coefficient (H) matrices
for (x in 1:100) {
  W_matrices_original[[x]] <- basis(nmf_results_original[[x]])
  W_matrices_filtered[[x]] <- basis(nmf_results_filtered[[x]])
  H_matrices_original[[x]] <- coef(nmf_results_original[[x]])
  H_matrices_filtered[[x]] <- coef(nmf_results_filtered[[x]])
}

# Normalise W and adjust H accordingly
for (x in 1:100) {
  if (!is.null(W_matrices_original[[x]]) && ncol(W_matrices_original[[x]]) > 0) {
    max_values_original <- apply(W_matrices_original[[x]], 2, max)
    max_values_original[max_values_original == 0] <- 1  
    W_matrices_original[[x]] <- W_matrices_original[[x]] / max_values_original
    H_matrices_original[[x]] <- H_matrices_original[[x]] * max_values_original
  }
  
  if (!is.null(W_matrices_filtered[[x]]) && ncol(W_matrices_filtered[[x]]) > 0) {
    max_values_filtered <- apply(W_matrices_filtered[[x]], 2, max)
    max_values_filtered[max_values_filtered == 0] <- 1  
    W_matrices_filtered[[x]] <- W_matrices_filtered[[x]] / max_values_filtered
    H_matrices_filtered[[x]] <- H_matrices_filtered[[x]] * max_values_filtered
  }
}

```

```{r}
# Cluster Prediction from H Matrices

predicted_clusters_original <- vector("list", 100)
predicted_clusters_filtered <- vector("list", 100)
H_clusters_original <- vector("list", 100)
H_clusters_filtered <- vector("list", 100)

# Assign samples to clusters based on H matrix values
for (x in 1:100) {

# Original dataset clustering
  H_matrix_original <- H_matrices_original[[x]]
  cluster_assignments_original <- apply(H_matrix_original, 2, which.max)


  names(cluster_assignments_original) <- colnames(H_matrix_original)
  predicted_clusters_original[[x]] <- cluster_assignments_original


  common_samples_original <- intersect(names(cluster_assignments_original), names(groundtruths))
  if (length(common_samples_original) > 0) {
    H_clusters_original[[x]] <- unify_labels(cluster_assignments_original[common_samples_original], groundtruths[common_samples_original])
  } else {
    H_clusters_original[[x]] <- rep(NA, length(cluster_assignments_original))
  }

# Filtered dataset clustering
  H_matrix_filtered <- H_matrices_filtered[[x]]
  cluster_assignments_filtered <- apply(H_matrix_filtered, 2, which.max)


  names(cluster_assignments_filtered) <- colnames(H_matrix_filtered)
  predicted_clusters_filtered[[x]] <- cluster_assignments_filtered


  common_samples_filtered <- intersect(names(cluster_assignments_filtered), names(groundtruths))
  if (length(common_samples_filtered) > 0) {
    H_clusters_filtered[[x]] <- unify_labels(cluster_assignments_filtered[common_samples_filtered], groundtruths[common_samples_filtered])
  } else {
    H_clusters_filtered[[x]] <- rep(NA, length(cluster_assignments_filtered))  
  }
}

```

```{r}
# Post-processing - Purity   

purity_post_original <- sapply(H_clusters_original, function(pred) {
  common_samples <- intersect(names(pred), names(groundtruths))
  if (length(common_samples) > 0) {
    calculate_purity(pred[common_samples], groundtruths[common_samples])
  } else {
    NA
  }
})

purity_post_filtered <- sapply(H_clusters_filtered, function(pred) {
  common_samples <- intersect(names(pred), names(groundtruths))
  if (length(common_samples) > 0) {
    calculate_purity(pred[common_samples], groundtruths[common_samples])
  } else {
    NA
  }
})

# Calculate mean post-purity and standard deviation 
purity_post_table <- data.frame(
  Condition = c("Original", "Filtered"),
  Average_Purity = c(
    mean(purity_post_original, na.rm = TRUE),
    mean(purity_post_filtered, na.rm = TRUE)
  ),
  SD_Purity = c(  
    ifelse(sum(!is.na(purity_post_original)) > 1, sd(purity_post_original, na.rm = TRUE), NA),
    ifelse(sum(!is.na(purity_post_filtered)) > 1, sd(purity_post_filtered, na.rm = TRUE), NA)
  )
)


print(purity_post_table)

```

```{r}
# Bootstrap - purity  


num_bootstrap <- 1000

# Perform bootstrapping
bootstrap_purity <- function(purity_values, num_samples) {
  bootstrapped_means <- numeric(num_samples)
  
  for (i in 1:num_samples) {
    resampled_values <- sample(purity_values, replace = TRUE)
    bootstrapped_means[i] <- mean(resampled_values, na.rm = TRUE)
  }
  
  return(bootstrapped_means)
}

# Bootstrap analysis for Original and Filtered purity values
boot_purity_original <- bootstrap_purity(purity_post_original, num_bootstrap)
boot_purity_filtered <- bootstrap_purity(purity_post_filtered, num_bootstrap)

# Compute standard deviation 
sd_boot_purity_original <- sd(boot_purity_original, na.rm = TRUE)
sd_boot_purity_filtered <- sd(boot_purity_filtered, na.rm = TRUE)


print(paste("SD of Bootstrapped Purity (Original):", sd_boot_purity_original))
print(paste("SD of Bootstrapped Purity (Filtered):", sd_boot_purity_filtered))


boot_purity_table <- data.frame(
  Condition = c("Original", "Filtered"),
  Mean_Purity = c(mean(boot_purity_original, na.rm = TRUE), mean(boot_purity_filtered, na.rm = TRUE)),
  SD_Purity = c(sd_boot_purity_original, sd_boot_purity_filtered)
)


print(boot_purity_table)

```

```{r}
# Plot bootstrap - purity

# dataframe for plotting
boot_purity_df <- data.frame(
  Purity = c(boot_purity_original, boot_purity_filtered),
  Condition = rep(c("Original", "Filtered"), each = length(boot_purity_original))
)

# Original comes first
boot_purity_df$Condition <- factor(boot_purity_df$Condition, levels = c("Original", "Filtered"))

# Boxplot of Bootstrap Purity Scores
ggplot(boot_purity_df, aes(x = Condition, y = Purity, fill = Condition)) +
  geom_boxplot(alpha = 0.6, outlier.shape = NA) +
  geom_jitter(width = 0.2, alpha = 0.4, size = 1.2) +  
  labs(title = "Bootstrap Analysis: Purity Scores",
       x = "Condition",
       y = "Purity Score") +
  theme_minimal() +
  scale_fill_manual(values = c("Original" = "lightgreen", "Filtered" = "darkgreen"))

```

```{r}
# Ensure no missing values before t-test
valid_idx <- !is.na(boot_purity_original) & !is.na(boot_purity_filtered)

# Perform paired t-test 
if (sum(valid_idx) > 1) {
  purity_ttest <- t.test(boot_purity_original[valid_idx], boot_purity_filtered[valid_idx], 
                          paired = TRUE, alternative = "two.sided")
} else {
  purity_ttest <- NULL
  print("Not enough valid paired samples for t-test.")
}

# t-test results
if (!is.null(purity_ttest)) {
  print(purity_ttest)
}
```
```{r}
# plot t-test - purity


purity_ttest_comparison <- data.frame(
  Condition = c("Original", "Filtered"),
  Average_Purity = c(mean(boot_purity_original, na.rm = TRUE), mean(boot_purity_filtered, na.rm = TRUE)),
  SD = c(sd(boot_purity_original, na.rm = TRUE), sd(boot_purity_filtered, na.rm = TRUE)) 
)


purity_ttest_comparison$Condition <- factor(purity_ttest_comparison$Condition, levels = c("Original", "Filtered"))

# Create the bar plot
ggplot(purity_ttest_comparison, aes(x = Condition, y = Average_Purity, fill = Condition)) +
  geom_bar(stat = "identity", position = position_dodge(), width = 0.6) +
  geom_errorbar(aes(ymin = Average_Purity - SD, ymax = Average_Purity + SD), width = 0.2) + 
  scale_fill_manual(values = c("Original" = "lightgreen", "Filtered" = "darkgreen")) +
  labs(title = "Bootstrap Analysis: Purity Comparison",
       x = "Condition", 
       y = "Average Bootstrapped Purity Score") +
  theme_minimal()

```
```{r}
# Post-processing - Adjusted Rand Index 

ARI_post_original <- sapply(H_clusters_original, function(pred) {
  common_samples <- intersect(names(pred), names(groundtruths))
  if (length(common_samples) > 0) {
    adjustedRandIndex(pred[common_samples], groundtruths[common_samples])
  } else {
    NA
  }
})

ARI_post_filtered <- sapply(H_clusters_filtered, function(pred) {
  common_samples <- intersect(names(pred), names(groundtruths))
  if (length(common_samples) > 0) {
    adjustedRandIndex(pred[common_samples], groundtruths[common_samples])
  } else {
    NA
  }
})


ARI_post_original_numeric <- as.numeric(unlist(ARI_post_original))
ARI_post_filtered_numeric <- as.numeric(unlist(ARI_post_filtered))

# Calculate mean post-ARI and standard deviation 
ARI_post_table <- data.frame(
  Condition = c("Original", "Filtered"),
  Average_ARI = c(
    mean(ARI_post_original_numeric, na.rm = TRUE),
    mean(ARI_post_filtered_numeric, na.rm = TRUE)
  ),
  SD_ARI = c(  
    ifelse(sum(!is.na(ARI_post_original_numeric)) > 1, sd(ARI_post_original_numeric, na.rm = TRUE), NA),
    ifelse(sum(!is.na(ARI_post_filtered_numeric)) > 1, sd(ARI_post_filtered_numeric, na.rm = TRUE), NA)
  )
)


print(ARI_post_table)

```

```{r}
# Bootstrap - ARI


num_bootstraps <- 1000  

# Bootstrap ARI values
boot_ARI_original <- numeric(num_bootstraps)
boot_ARI_filtered <- numeric(num_bootstraps)

# bootstrapping for Original ARI
for (i in 1:num_bootstraps) {
  boot_sample <- sample(ARI_post_original_numeric, replace = TRUE)
  boot_ARI_original[i] <- mean(boot_sample, na.rm = TRUE)
}

# bootstrapping for Filtered ARI
for (i in 1:num_bootstraps) {
  boot_sample <- sample(ARI_post_filtered_numeric, replace = TRUE)
  boot_ARI_filtered[i] <- mean(boot_sample, na.rm = TRUE)
}

# Compute standard deviation 
SD_boot_ARI_original <- sd(boot_ARI_original, na.rm = TRUE)
SD_boot_ARI_filtered <- sd(boot_ARI_filtered, na.rm = TRUE)


print(paste("SD of Bootstrapped ARI (Original):", SD_boot_ARI_original))
print(paste("SD of Bootstrapped ARI (Filtered):", SD_boot_ARI_filtered))


boot_ARI_table <- data.frame(
  Condition = c("Original", "Filtered"),
  Mean_ARI = c(mean(boot_ARI_original, na.rm = TRUE), mean(boot_ARI_filtered, na.rm = TRUE)),
  SD_ARI = c(SD_boot_ARI_original, SD_boot_ARI_filtered)
)


print(boot_ARI_table)


```

```{r}
# Plot bootstrapping - ARI


boot_ARI_df <- data.frame(
  ARI = c(boot_ARI_original, boot_ARI_filtered),
  Condition = rep(c("Original", "Filtered"), each = length(boot_ARI_original))
)


boot_ARI_df$Condition <- factor(boot_ARI_df$Condition, levels = c("Original", "Filtered"))

# Create a boxplot 
ggplot(boot_ARI_df, aes(x = Condition, y = ARI, fill = Condition)) +
  geom_boxplot(alpha = 0.6, outlier.shape = NA) +
  geom_jitter(width = 0.2, alpha = 0.4, size = 1.2) +  
  labs(title = "Bootstrap Analysis: ARI Scores",
       x = "Condition",
       y = "Adjusted Rand Index (ARI)") +
  theme_minimal() +
  scale_fill_manual(values = c("Original" = "lightgreen", "Filtered" = "darkgreen"))

```

```{r}
# ARI - t-test

# only valid  ARI values
valid_idx <- !is.na(boot_ARI_original) & !is.na(boot_ARI_filtered)

# Perform paired t-test 
if (sum(valid_idx) > 1) {
  ari_ttest <- t.test(boot_ARI_original[valid_idx], boot_ARI_filtered[valid_idx], 
                      paired = TRUE, alternative = "two.sided")
  print(ari_ttest)
} else {
  print("Not enough valid paired samples for t-test.")
}

```

```{r}
# Plot t-test - ARI


ari_ttest_comparison <- data.frame(
  Condition = c("Original", "Filtered"),
  Average_ARI = c(mean(boot_ARI_original, na.rm = TRUE), mean(boot_ARI_filtered, na.rm = TRUE)),
  SD_ARI = c(sd(boot_ARI_original, na.rm = TRUE), sd(boot_ARI_filtered, na.rm = TRUE))
)


ari_ttest_comparison$Condition <- factor(ari_ttest_comparison$Condition, levels = c("Original", "Filtered"))

# Perform paired t-test
valid_idx <- !is.na(boot_ARI_original) & !is.na(boot_ARI_filtered)

if (sum(valid_idx) > 1) {
  ari_ttest <- t.test(boot_ARI_original[valid_idx], boot_ARI_filtered[valid_idx], 
                      paired = TRUE, alternative = "two.sided")
} else {
  ari_ttest <- NULL
  print("Not enough valid paired samples for t-test.")
}

# Bar plot with error bars
ggplot(ari_ttest_comparison, aes(x = Condition, y = Average_ARI, fill = Condition)) +
  geom_bar(stat = "identity", position = position_dodge(), width = 0.6) +
  geom_errorbar(aes(ymin = Average_ARI - SD_ARI, ymax = Average_ARI + SD_ARI), width = 0.2) +
  scale_fill_manual(values = c("Original" = "lightgreen", "Filtered" = "darkgreen")) +
  labs(title = "T-Test Comparison of ARI: Original vs. Filtered",
       x = "Condition",
       y = "Average ARI") +
  theme_minimal()


if (!is.null(ari_ttest)) {
  print(ari_ttest)
}

# comparison table
print(ari_ttest_comparison)



```

```{r}
# Post-processing - Normalised Mutual Information 

NMI_post_original <- sapply(H_clusters_original, function(pred) {
  common_samples <- intersect(names(pred), names(groundtruths))
  if (length(common_samples) > 0) {
    NMI(pred[common_samples], groundtruths[common_samples])
  } else {
    NA
  }
})

NMI_post_filtered <- sapply(H_clusters_filtered, function(pred) {
  common_samples <- intersect(names(pred), names(groundtruths))
  if (length(common_samples) > 0) {
    NMI(pred[common_samples], groundtruths[common_samples])
  } else {
    NA
  }
})


NMI_post_original_numeric <- as.numeric(unlist(NMI_post_original))
NMI_post_filtered_numeric <- as.numeric(unlist(NMI_post_filtered))

# Calculate mean post-NMI and standard deviation 
NMI_post_table <- data.frame(
  Condition = c("Original", "Filtered"),
  Average_NMI = c(
    mean(NMI_post_original_numeric, na.rm = TRUE),
    mean(NMI_post_filtered_numeric, na.rm = TRUE)
  ),
  SD_NMI = c(
    ifelse(sum(!is.na(NMI_post_original_numeric)) > 1, sd(NMI_post_original_numeric, na.rm = TRUE), NA),
    ifelse(sum(!is.na(NMI_post_filtered_numeric)) > 1, sd(NMI_post_filtered_numeric, na.rm = TRUE), NA)
  )
)


print(NMI_post_table)

```

```{r}
# Bootstrap - NMI

num_bootstraps <- 1000  

# compute bootstrap samples
bootstrap_nmi <- function(nmi_values, num_samples) {
  boot_results <- replicate(num_bootstraps, mean(sample(nmi_values, num_samples, replace = TRUE), na.rm = TRUE))
  return(boot_results)
}

# Bootstrap on original and filtered NMI values
boot_nmi_original <- bootstrap_nmi(NMI_post_original_numeric, length(NMI_post_original_numeric))
boot_nmi_filtered <- bootstrap_nmi(NMI_post_filtered_numeric, length(NMI_post_filtered_numeric))

# standard deviation 
sd_boot_nmi_original <- sd(boot_nmi_original, na.rm = TRUE)
sd_boot_nmi_filtered <- sd(boot_nmi_filtered, na.rm = TRUE)


boot_nmi_table <- data.frame(
  Condition = c("Original", "Filtered"),
  Mean_Bootstrapped_NMI = c(mean(boot_nmi_original, na.rm = TRUE), mean(boot_nmi_filtered, na.rm = TRUE)),
  SD_Bootstrapped_NMI = c(sd_boot_nmi_original, sd_boot_nmi_filtered)
)


print(boot_nmi_table)
```

```{r}
# Plot bootstrap NMI


boot_nmi_df <- data.frame(
  NMI = c(boot_nmi_original, boot_nmi_filtered),
  Condition = rep(c("Original", "Filtered"), each = length(boot_nmi_original))
)


boot_nmi_df$Condition <- factor(boot_nmi_df$Condition, levels = c("Original", "Filtered"))

# Boxplot 
ggplot(boot_nmi_df, aes(x = Condition, y = NMI, fill = Condition)) +
  geom_boxplot(alpha = 0.6, outlier.shape = NA) +
  geom_jitter(width = 0.2, alpha = 0.4, size = 1.2) +  
  labs(title = "Bootstrap Analysis: NMI Scores",
       x = "Condition",
       y = "NMI Score") +
  theme_minimal() +
  scale_fill_manual(values = c("Original" = "lightgreen", "Filtered" = "darkgreen"))

```

```{r}
#T-test - NMI

# Perform a two-sided t-test 
nmi_ttest <- t.test(boot_nmi_original, boot_nmi_filtered, 
                    paired = TRUE, alternative = "two.sided")


print(nmi_ttest)


nmi_ttest_comparison <- data.frame(
  Condition = factor(c("Original", "Filtered"), levels = c("Original", "Filtered")),  
  Average_NMI = c(mean(boot_nmi_original, na.rm = TRUE), mean(boot_nmi_filtered, na.rm = TRUE)),
  SD = c(sd(boot_nmi_original, na.rm = TRUE), sd(boot_nmi_filtered, na.rm = TRUE))  
)

# View results
print(nmi_ttest_comparison)

```
```{r}
# Plot t-test NMI

# Plot results
ggplot(nmi_ttest_comparison, aes(x = Condition, y = Average_NMI, fill = Condition)) +
  geom_bar(stat = "identity", position = position_dodge(), width = 0.6) +  
  geom_errorbar(aes(ymin = Average_NMI - SD, ymax = Average_NMI + SD), width = 0.2) + 
  scale_fill_manual(values = c("Original" = "lightgreen", "Filtered" = "darkgreen")) +
  labs(title = "Bootstrapped NMI: Original vs. Filtered",
       x = "Condition",
       y = "Average NMI") +
  theme_minimal()



```

```{r}
# Clustering Errors

# number of genes to test
gene_counts <- seq(500, 873, by = 100)  

# store clustering errors
clustering_errors_original <- c()
clustering_errors_filtered <- c()


set.seed(123)

for (num_genes in gene_counts) {
  
  selected_genes <- head(order(apply(exprs, 1, var), decreasing = TRUE), num_genes)
  exprs_subset <- exprs[selected_genes, ]
  
  
  selected_genes_filtered <- head(order(apply(exprs_filtered_ages, 1, var), decreasing = TRUE), num_genes)
  exprs_filtered_subset <- exprs_filtered_ages[selected_genes_filtered, ]
  
# Run NMF 
  nmf_result_original <- nmf(exprs_subset, rank = 2, nrun = 5, seed = "random")
  nmf_result_filtered <- nmf(exprs_filtered_subset, rank = 2, nrun = 5, seed = "random")
  
# Extract H matrices and assign clusters
  H_matrix_original <- coef(nmf_result_original)
  predicted_clusters_original <- apply(H_matrix_original, 2, which.max)

  H_matrix_filtered <- coef(nmf_result_filtered)
  predicted_clusters_filtered <- apply(H_matrix_filtered, 2, which.max)
  

  common_samples <- intersect(names(predicted_clusters_original), names(groundtruths))
  groundtruths_valid <- groundtruths[common_samples]
  predicted_clusters_original <- predicted_clusters_original[common_samples]
  predicted_clusters_filtered <- predicted_clusters_filtered[common_samples]
  
# Clustering error 
  ari_original <- adjustedRandIndex(predicted_clusters_original, groundtruths_valid)
  ari_filtered <- adjustedRandIndex(predicted_clusters_filtered, groundtruths_valid)
  

  clustering_errors_original <- c(clustering_errors_original, 1 - ari_original)
  clustering_errors_filtered <- c(clustering_errors_filtered, 1 - ari_filtered)
}


plot_data <- data.frame(
  Number_of_Genes = rep(gene_counts, 2),
  Errors = c(clustering_errors_original, clustering_errors_filtered),
  Method = rep(c("Original NMF", "Filtered NMF"), each = length(gene_counts))
)


plot_data$Method <- factor(plot_data$Method, levels = c("Original NMF", "Filtered NMF"))

# Plot clustering errors
ggplot(plot_data, aes(x = Number_of_Genes, y = Errors, color = Method, linetype = Method)) +
  geom_line(linewidth = 1) +  
  scale_linetype_manual(values = c("Original NMF" = "solid", "Filtered NMF" = "dashed")) +
  scale_color_manual(values = c("Original NMF" = "blue", "Filtered NMF" = "red")) +
  labs(title = "Comparison of Clustering Errors: Original vs. Filtered NMF",
       x = "Number of Genes",
       y = "Clustering Errors") +
  theme_minimal()

```

